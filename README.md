![Python](https://img.shields.io/badge/Python-3.11-blue)
![Model](https://img.shields.io/badge/Model-XGBoost-success)
![License](https://img.shields.io/badge/License-MIT-green)

# ğŸ›ï¸ Olist Customer Segmentation & CLV Prediction

> End-to-end customer segmentation and lifetime value (CLV) prediction pipeline built on the **Brazilian E-Commerce Public Dataset by Olist**, integrating machine learning, probabilistic modeling, and marketing uplift simulation.

---

## ğŸ“˜ Project Overview

This project builds a **full-stack data science pipeline** for customer value prediction and segmentation in an e-commerce context.  
Using real Olist transaction data (100K+ orders from 2016â€“2018), it predicts each customer's **future 180-day CLV**, builds interpretable customer segments, and designs **ROI-driven marketing strategies** based on uplift modeling.

---

## ğŸ§© Key Features

- **ğŸ”„ ETL & Feature Engineering**  
  Consolidated 9 raw Olist tables into 95K customer-level records.  
  Engineered behavioral, RFM, payment, and review-based features.

- **ğŸ¤– ML-based CLV Model**  
  Trained an `XGBoostRegressor` to predict future 180-day gross profit,  
  validated through rolling time-based splits (Spearman = **0.89**, MAE = **3.04**).

- **ğŸ“ˆ Probabilistic Baseline (BG/NBD + Gamma-Gamma)**  
  Built interpretable benchmark models for audit & financial alignment.

- **ğŸ§  Customer Segmentation**  
  Unsupervised learning via `KMeans` and `HDBSCAN`,  
  yielding actionable customer cohorts by value and frequency.

- **ğŸ“Š Uplift Simulation & Experimentation**  
  Designed treatment-control allocation by CLV tier,  
  quantified incremental ROI uplift (~+15â€“20%).

- **ğŸ“‘ Automated Reporting**  
  Generates PowerPoint reports (`python-pptx`) with CLV distribution,  
  segmentation heatmaps, uplift allocation charts, and business insights.

---

## ğŸ§± Project Architecture

olist-clv-seg/
â”‚
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ etl/                     # Data cleaning and merging (9 Olist tables)
â”‚   â”œâ”€â”€ features/                # Feature engineering (RFM, reviews, payments)
â”‚   â”œâ”€â”€ pipeline/                # Model training, scoring, segmentation
â”‚   â”œâ”€â”€ reports/                 # Auto PPT generation and visualization
â”‚   â””â”€â”€ common/                  # Logging, config, and utility functions
â”‚
â”œâ”€â”€ config/                      # YAML config files for data paths & params
â”œâ”€â”€ data/                        # (ignored) raw, interim, features, outputs
â”œâ”€â”€ models/                      # Saved XGBoost & BG/NBD models
â”œâ”€â”€ reports/                     # Auto-generated PowerPoint deck
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md

## âš™ï¸ How to Run
---
```bash
# 1ï¸âƒ£ Create environment
conda create -n olist-clv python=3.11
conda activate olist-clv
pip install -r requirements.txt

# 2ï¸âƒ£ Generate features
python -m src.etl.build_customer_wide
python -m src.features.build_customer_features

# 3ï¸âƒ£ Train ML-based CLV model
python -m src.pipeline.train_clv_ml

# 4ï¸âƒ£ Batch scoring & segmentation
python -m src.pipeline.batch_scoring
python -m src.pipeline.clv_segmentation_merge

# 5ï¸âƒ£ Generate automated PowerPoint report
python -m src.reports.generate_ppt


ğŸ¯ Business Impact
	â€¢	Identified top 20% customers contributing ~80% of total predicted CLV
	â€¢	Enabled marketing budget reallocation to focus on high-value segments
	â€¢	Simulated uplift experiment showed +15â€“20% incremental ROI
	â€¢	Established reproducible pipeline for weekly scoring and model retraining

â¸»

ğŸ§  Tools & Libraries

Python Â· Pandas Â· Scikit-learn Â· XGBoost Â· Lifetimes Â· HDBSCAN Â· SHAP Â· Matplotlib Â· python-pptx Â· Prefect

â¸»

ğŸ“„ Description (for GitHub short tagline)

Machine learningâ€“driven customer lifetime value prediction and segmentation pipeline for e-commerce marketing optimization.

â¸»

ğŸ‘¤ Author

Charlie Shi
Data Science & Business Analytics
GitHub: charlieshi46ï¿¼

â¸»

âœ… Next Steps
	1.	Add a project banner or architecture diagram (reports/figures/diagram.png)
	2.	Connect the repo to a requirements.txt badge / CI pipeline
	3.	Optionally host a Streamlit dashboard for interactive demo